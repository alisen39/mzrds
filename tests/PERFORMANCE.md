# 性能测试报告

## 测试环境

- Redis 服务器: 192.168.31.12:6379
- Python 版本: 3.13.5
- redis-py 版本: 7.1.0

## 测试场景

### 1. 大数据集生成性能

**测试**: 生成 10,000 条数据到 zset

- **耗时**: ~0.30 秒
- **速度**: ~33,000 条/秒
- **批量大小**: 1,000 条/批

### 2. zscan 性能测试（10,000 条数据）

#### 2.1 单次 zscan
- **count=100**: 返回 ~102 条数据，耗时 ~0.01 秒
- **说明**: Redis 的 count 是提示值，实际返回可能略多

#### 2.2 zscan_iter 自动翻页
- **总耗时**: ~0.92 秒
- **遍历数据量**: 10,000 条
- **平均速度**: ~10,900 条/秒

#### 2.3 带模式匹配的 zscan_iter
- **模式**: `member_*000`（匹配 10 条）
- **耗时**: ~0.68 秒
- **说明**: 模式匹配需要扫描所有数据，性能略低

### 3. 不同 count 值的性能对比

测试数据量: 10,000 条

| count 值 | 耗时（秒） | 速度（条/秒） | 说明 |
|---------|-----------|-------------|------|
| 10      | 5.59      | ~1,800      | 网络往返次数多，性能最低 |
| 100     | 0.78      | ~12,800     | 平衡性能和内存使用 |
| 500     | 0.32      | ~31,400     | 推荐值，性能优秀 |
| 1000    | 0.21      | ~48,000     | 性能最佳，但内存占用较大 |

**结论**: 
- 对于大数据集，建议使用 `count=500` 或 `count=1000`
- `count=100` 是性能和内存的平衡点
- `count=10` 仅适用于小数据集或对内存敏感的场景

### 4. 多 zset 性能测试

**测试**: 10 个 zset，每个 1,000 条数据

- **数据生成**: ~0.25 秒
- **遍历所有 zset**: ~0.78 秒
- **总数据量**: 10,000 条
- **平均速度**: ~12,800 条/秒

### 5. 所有 scan 命令性能对比（5,000 条数据）

| 命令   | 耗时（秒） | 速度（条/秒） |
|--------|-----------|-------------|
| scan   | 0.31      | ~16,100     |
| hscan  | 0.34      | ~14,700     |
| sscan  | 0.32      | ~15,600     |
| zscan  | 0.39      | ~12,800     |

**说明**: zscan 稍慢是因为需要返回分数信息

## 性能优化建议

1. **使用合适的 count 值**: 
   - 小数据集（<1,000）: `count=100`
   - 中等数据集（1,000-10,000）: `count=500`
   - 大数据集（>10,000）: `count=1000`

2. **批量操作**: 
   - 写入数据时使用批量操作（如 `zadd` 的字典参数）
   - 批量大小建议 1,000 条

3. **避免模式匹配**: 
   - 如果可能，尽量避免在 scan 时使用模式匹配
   - 模式匹配需要扫描所有数据，性能较低

4. **使用自动翻页**: 
   - `zscan_iter` 等迭代器会自动处理翻页
   - 比手动管理 cursor 更高效

## 运行性能测试

```bash
# 运行所有冒烟测试和性能测试
uv run pytest tests/ -v -m smoke -s

# 运行特定测试
uv run pytest tests/test_smoke.py::test_zscan_performance_with_large_dataset -v -s
```

